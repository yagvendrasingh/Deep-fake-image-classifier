{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation, Dropout, Average , BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score , f1_score\n",
    "import scipy\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from keras.utils import to_categorical\n",
    "import dlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Final_function 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function(x):\n",
    "    \"\"\"\n",
    "    final function 1st gives the output probablity\n",
    "    on given raw input data.\n",
    "    \"\"\"\n",
    "    image = (x)\n",
    "    #loding and initializing the face detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # loding and initializing the pretrained facial landmark detector model from the dlib lib \n",
    "    sp = dlib.shape_predictor(\"C:\\\\Users\\\\my pc\\\\Downloads\\\\Extra files\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    #read the image using openCV library\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    \n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces\n",
    "    \n",
    "    det = detector(img, 1)\n",
    "        \n",
    "    # Find the 5 face landmarks we need to do the alignment.\n",
    "    faces = dlib.full_object_detections()\n",
    "    for detection in det:\n",
    "        faces.append(sp(img, detection))\n",
    "    try:\n",
    "        # Get the aligned face images\n",
    "        images = dlib.get_face_chips(img, faces, size=64)# wiht the size of 64 for our model.\n",
    "    except RuntimeError:\n",
    "        print(\"no face found\")\n",
    "        pass\n",
    "    #converting detected and aligned faces into the gray scale.\n",
    "    for image in images:\n",
    "        a = cv2.cvtColor((image), cv2.COLOR_RGB2GRAY)\n",
    "        b = a/255\n",
    "        b = b.reshape(1 , 64 , 64 , 1)\n",
    "    \n",
    "    X_test = b\n",
    "    #creating the model\n",
    "    model = tf.keras.models.load_model('C:\\\\Users\\\\my pc\\\\project_first final model')\n",
    "    model.load_weights(\"C:\\\\Users\\\\my pc\\\\Downloads\\\\CG_Face_Modified.h5\")\n",
    "    re = (model.predict(X_test))\n",
    "    re = re.flatten()\n",
    "    #print(re)\n",
    "    idx = np.argmax(re)\n",
    "    b = \" \"\n",
    "    if idx==1:\n",
    "        b = \"real\"\n",
    "    else:\n",
    "        b = \"Fake\"\n",
    "    return print(\"The raw image is \"+b+\" with the probablity of:\" ,re[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw image is Fake with the probablity of: 0.7362513\n"
     ]
    }
   ],
   "source": [
    "final_output = final_function(\"C:\\\\Users\\\\my pc\\\\Pictures\\\\Screenshots\\\\eg4.PNG\")\n",
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final_function2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function2(x , y):\n",
    "    \"\"\"\n",
    "    This function gives the result with the final \n",
    "    metric.\n",
    "    \"\"\"\n",
    "    image = (x)\n",
    "    #loding and initializing the face detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # loding and initializing the pretrained facial landmark detector model from the dlib lib \n",
    "    sp = dlib.shape_predictor(\"C:\\\\Users\\\\my pc\\\\Downloads\\\\Extra files\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    #read the image using openCV library\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    \n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces\n",
    "    \n",
    "    det = detector(img, 1)\n",
    "        \n",
    "    # Find the 5 face landmarks we need to do the alignment.\n",
    "    faces = dlib.full_object_detections()\n",
    "    for detection in det:\n",
    "        faces.append(sp(img, detection))\n",
    "    try:\n",
    "        # Get the aligned face images\n",
    "        images = dlib.get_face_chips(img, faces, size=64)# wiht the size of 64 for our model.\n",
    "    except RuntimeError:\n",
    "        print(\"no face found\")\n",
    "        pass\n",
    "    #converting detected and aligned faces into the gray scale.\n",
    "    for image in images:\n",
    "        a = cv2.cvtColor((image), cv2.COLOR_RGB2GRAY)\n",
    "        b = a/255\n",
    "        b = b.reshape(1 , 64 , 64 , 1)\n",
    "    \n",
    "    X_test = b\n",
    "    lst = [\"real\" , \"fake\"]\n",
    "    if y in lst:\n",
    "        if y==\"real\":\n",
    "            y_true =  np.array([0 , 1])\n",
    "            y_true = y_true.reshape(1,2)\n",
    "        elif y ==\"fake\":\n",
    "            y_true = np.array([1 , 0])\n",
    "            y_true = y_true.reshape(1,2)\n",
    "        #creating the model\n",
    "        model = tf.keras.models.load_model('C:\\\\Users\\\\my pc\\\\project_first final model')\n",
    "        model.load_weights(\"C:\\\\Users\\\\my pc\\\\Downloads\\\\CG_Face_Modified.h5\")\n",
    "        result = model.evaluate(X_test , y_true)\n",
    "        dt = dict(zip(model.metrics_names, result))\n",
    "        return print(\"The accuracy of being \"+y+ \" is\", dt[\"accuracy\"]*100,str(\"%\"))\n",
    "    else:\n",
    "        print(\"Please enter the valid string as real or fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 987us/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1988 - accuracy: 1.0000\n",
      "The accuracy of being real is 100.0 %\n",
      "6.38 s ± 669 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "final_output2 = final_function2(\"C:\\\\Users\\\\my pc\\\\Pictures\\\\Screenshots\\\\project.PNG\" , \"real\" )\n",
    "final_output2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
